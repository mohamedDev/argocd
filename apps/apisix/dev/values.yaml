# Configuration APISIX pour GKE

replicaCount: 2

image:
  repository: apache/apisix
  tag: "3.13.0-ubuntu" # dernière version stable du chart officiel
  pullPolicy: IfNotPresent

# Service configuration
service:
  type: NodePort
  http:
    enabled: true
    servicePort: 80
    containerPort: 9080
    nodePort: 30088
  tls:
    servicePort: 443
    containerPort: 9443
    nodePort: 30443

# Ingress (désactivé ici, GKE LoadBalancer sera plus adapté)
ingress:
  enabled: false

# Resources (équilibrées pour GKE n1-standard-2)
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# Autoscaling horizontal (HPA)
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 70

externalEtcd:
  # The host now uses the Fully Qualified Domain Name (FQDN):
  # [service-name].[namespace].svc.cluster.local
  host:
    - http://etcd-service.apisix-etcd-dev.svc.cluster.local:2379

  # Since your etcd deployment has ALLOW_NONE_AUTHENTICATION set to "yes", 
  # we set the user and password fields to empty strings to disable authentication.
  user: ""
  password: ""

  # We keep these empty as no secret is involved for authentication.
  existingSecret: ""
  secretPasswordKey: "etcd-root-password"
# etcd embarqué (éviter en prod GKE, privilégier un etcd externe ou Cloud Spanner/Cloud SQL)
etcd:
  enabled: false
  # replicaCount: 1 # Réduire à 1 pour local-path
  # persistence:
  #   enabled: true
  #   storageClass: "local-path"
  #   size: 8Gi

# APISIX core config
apisix:
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9091"
    prometheus.io/path: "/apisix/prometheus/metrics"
  enableHTTP2: true
  enableIPv6: false

  ssl:
    enabled: true
    containerPort: 9443
    enableHTTP3: false

  admin:
    enabled: true
    enable_admin_ui: true
    type: ClusterIP
    port: 9180
    servicePort: 9180
    cors: true
    credentials:
      admin: "changeme-admin-key"
      viewer: "changeme-viewer-key"
      secretName: "" # tu peux mettre un secret GKE si tu veux externaliser les clés
    allow:
      ipList:
        - 10.0.0.0/8 # CIDR interne GKE
        - 127.0.0.1/24 # localhost

  plugins:
    - api-breaker
    - authz-keycloak
    - basic-auth
    - batch-requests
    - consumer-restriction
    - cors
    - echo
    - fault-injection
    - grpc-transcode
    - hmac-auth
    - http-logger
    - ip-restriction
    - jwt-auth
    - key-auth
    - limit-conn
    - limit-count
    - limit-req
    - node-status
    - openid-connect
    - prometheus
    - proxy-cache
    - proxy-mirror
    - proxy-rewrite
    - redirect
    - referer-restriction
    - request-id
    - request-validation
    - response-rewrite
    - serverless-pre-function
    - serverless-post-function
    - sls-logger
    - syslog
    - tcp-logger
    - udp-logger
    - uri-blocker
    - wolf-rbac
    - zipkin
    - server-info
    - traffic-split
    - kafka-logger

# Monitoring
metrics:
  serviceMonitor:
    enabled: false

# Spécifique GKE
nodeSelector:
  kubernetes.io/os: linux

tolerations: []

# Pas d’anti-affinité forcée (utile sur petit cluster GKE)
affinity: {}
